{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1.67%\n",
      "Progress: 3.33%\n",
      "Progress: 5.00%\n",
      "Progress: 6.67%\n",
      "Progress: 8.33%\n",
      "Progress: 10.00%\n",
      "Progress: 11.67%\n",
      "Progress: 13.33%\n",
      "Progress: 15.00%\n",
      "Progress: 16.67%\n",
      "Progress: 18.33%\n",
      "Progress: 20.00%\n",
      "Progress: 21.67%\n",
      "Progress: 23.33%\n",
      "Progress: 25.00%\n",
      "Progress: 26.67%\n",
      "Progress: 28.33%\n",
      "Progress: 30.00%\n",
      "Progress: 31.67%\n",
      "Progress: 33.33%\n",
      "Progress: 35.00%\n",
      "Progress: 36.67%\n",
      "Progress: 38.33%\n",
      "Progress: 40.00%\n",
      "Progress: 41.67%\n",
      "Progress: 43.33%\n",
      "Progress: 45.00%\n",
      "Progress: 46.67%\n",
      "Progress: 48.33%\n",
      "Progress: 50.00%\n",
      "Progress: 51.67%\n",
      "Progress: 53.33%\n",
      "Progress: 55.00%\n",
      "Progress: 56.67%\n",
      "Progress: 58.33%\n",
      "Progress: 60.00%\n",
      "Progress: 61.67%\n",
      "Progress: 63.33%\n",
      "Progress: 65.00%\n",
      "Progress: 66.67%\n",
      "Progress: 68.33%\n",
      "Progress: 70.00%\n",
      "Progress: 71.67%\n",
      "Progress: 73.33%\n",
      "Progress: 75.00%\n",
      "Progress: 76.67%\n",
      "Progress: 78.33%\n",
      "Progress: 80.00%\n",
      "Progress: 81.67%\n",
      "Progress: 83.33%\n",
      "Progress: 85.00%\n",
      "Progress: 86.67%\n",
      "Progress: 88.33%\n",
      "Progress: 90.00%\n",
      "Progress: 91.67%\n",
      "Progress: 93.33%\n",
      "Progress: 95.00%\n",
      "Progress: 96.67%\n",
      "Progress: 98.33%\n",
      "Progress: 100.00%\n",
      "Size of data set, columns: 13 and rows: 30000\n"
     ]
    }
   ],
   "source": [
    "# Import python packages\n",
    "from setup import Setup\n",
    "from utilities import Utilities\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from data_processing import DataProcessing\n",
    "from data_visualization import DataVisualization\n",
    "from feature_engineering import FeatureEngineering\n",
    "from data_split import DataSplit\n",
    "from xgboost_model import XGBoostModel\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize class\n",
    "SU = Setup(cfg_filepath = 'config.yaml')\n",
    "\n",
    "# Get the paths\n",
    "source_path = SU.source_path\n",
    "meta_path = SU.meta_path\n",
    "destination_path = SU.destination_path\n",
    "plot_path = SU.plot_path\n",
    "result_path = SU.result_path\n",
    "model_folder_path = SU.model_folder_path\n",
    "model_param_path = SU.param_path\n",
    "model_hyperparam_path = SU.hyperparam_path\n",
    "\n",
    "# Initialize class\n",
    "UT = Utilities(destination_path)\n",
    "\n",
    "# Read files\n",
    "meta_data = UT.read_file(meta_path)\n",
    "model_param = UT.read_file(model_param_path)\n",
    "model_hyperparam = UT.read_file(model_hyperparam_path)\n",
    "\n",
    "# Initialize classes\n",
    "DP = DataProcessing(target_sr=8000)\n",
    "DV = DataVisualization(plot_path)\n",
    "FE = FeatureEngineering()\n",
    "DS = DataSplit()\n",
    "DS = DataSplit(test_size=0.1, val_size=0.1)\n",
    "\n",
    "# Create empty dataframe\n",
    "df = UT.create_dataframe(None, column_names=[\"gender\", \"digit\"])\n",
    "\n",
    "# Specify total number of folders in source path\n",
    "all_folders = len(next(os.walk(source_path))[1])+1\n",
    "\n",
    "# Loop over audio recordings in the source path\n",
    "for i in range(1, all_folders):\n",
    "    # Show progress\n",
    "    UT.loop_progress(i, all_folders-1)\n",
    "\n",
    "    # Assign source temp\n",
    "    src_temp = os.path.join(source_path, f\"{i:02d}\")\n",
    "    filepath_filename = sorted(glob.glob(os.path.join(src_temp, \"*.wav\")))\n",
    "\n",
    "    # Loop over files in directory\n",
    "    for file in filepath_filename:\n",
    "        # Split file string\n",
    "        dig, vp, rep = file.rstrip(\".wav\").split(\"/\")[-1].split(\"_\")\n",
    "\n",
    "        # Read audio data\n",
    "        fs, audio_data = UT.read_audio(file)\n",
    "\n",
    "        # Plot audio signal\n",
    "        audio_name = f\"audio_{dig[-1]}_{vp}_{rep}.png\"\n",
    "        #DV.plot_audio(fs, audio_data, audio_name)\n",
    "\n",
    "        # Plot STFT of audio signal\n",
    "        stft_name = f\"stft_{dig[-1]}_{vp}_{rep}.png\"\n",
    "        #DV.plot_stft(fs, audio_data, stft_name)\n",
    "\n",
    "        # Play audio signal\n",
    "        #DV.play_audio(file)\n",
    "\n",
    "        # Resample audio data\n",
    "        audio_data = DP.resample_data(fs, audio_data)\n",
    "\n",
    "        # Zero padding audio data\n",
    "        audio_data = DP.zero_pad(audio_data)\n",
    "\n",
    "        # FFT audio data\n",
    "        fft_data = DP.fft_data(audio_data)\n",
    "\n",
    "        # Apply bandpass filter\n",
    "        bp_data = DP.bandpass_filter(fft_data, low_threshold=100, high_threshold=250)\n",
    "\n",
    "        # Feature creation\n",
    "        features = DP.feature_creation(fft_data)\n",
    "\n",
    "        # Normalize features\n",
    "        n_features = DP.normalize_features(features)\n",
    "\n",
    "        # Add gender and digit label\n",
    "        features = DP.add_gender(n_features, meta_data[vp][\"gender\"])\n",
    "        features = DP.add_digit(n_features, dig[-1])\n",
    "\n",
    "        # Append new dict values to the DataFrame\n",
    "        df = df.append(features, ignore_index=True)\n",
    "        #break\n",
    "\n",
    "# Save data to CSV\n",
    "csv_name = \"features_data.csv\"\n",
    "UT.save_df_to_csv(df, csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set, columns: 9 and rows: 24000\n",
      "Size of validation set, columns: 9 and rows: 3000\n",
      "Size of validation set, columns: 9 and rows: 3000\n",
      "Number of female audio recordings: 6000\n",
      "Number of male audio recordings: 24000\n",
      "Accuracy: 82.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load CSV file into dataframe\n",
    "df = UT.csv_to_df(csv_name)\n",
    "\n",
    "# Show size of dataset\n",
    "df_size = UT.df_shape(df)\n",
    "print(f\"Size of data set, columns: {df_size[1]} and rows: {df_size[0]}\")\n",
    "\n",
    "# Remove digit column\n",
    "df = UT.remove_column(df, \"digit\")\n",
    "\n",
    "# Create label column where 'female' is 0 and 'male' is 1\n",
    "df = FE.create_label_column(df)\n",
    "\n",
    "# Plot column distribution\n",
    "plot_name = \"column_distribution.png\"\n",
    "DV.column_distribution(df, plot_name)\n",
    "\n",
    "# Leave target columns out\n",
    "columns_to_leave_out = [\"label\"]\n",
    "\n",
    "# Remove constant columns\n",
    "df = FE.remove_constant_columns(df, columns_to_leave_out)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = FE.pearson_correlation(df, columns_to_leave_out)\n",
    "\n",
    "# Plot correlation matrix\n",
    "corr_name = \"correlation_matrix.png\"\n",
    "DV.plot_corr_matrix(corr_matrix, corr_name)\n",
    "\n",
    "# Assign correlation threshold\n",
    "threshold = 0.95\n",
    "\n",
    "# Remove correlated columns\n",
    "df = FE.remove_correlated_columns(df, threshold, columns_to_leave_out)\n",
    "\n",
    "# Save data to CSV\n",
    "csv_name = \"final_data.csv\"\n",
    "UT.save_df_to_csv(df, csv_name)\n",
    "\n",
    "# Load CSV file into dataframe\n",
    "df = UT.csv_to_df(csv_name)\n",
    "\n",
    "# Split data into training (80%), validation (10%), and test set (10%)\n",
    "train_df, val_df, test_df = DS.split(df, \"label\")\n",
    "\n",
    "# Show size of datasets\n",
    "train_size = UT.df_shape(train_df)\n",
    "val_size = UT.df_shape(val_df)\n",
    "test_size = UT.df_shape(test_df)\n",
    "print(f\"Size of training set, columns: {train_size[1]} and rows: {train_size[0]}\")\n",
    "print(f\"Size of validation set, columns: {val_size[1]} and rows: {val_size[0]}\")\n",
    "print(f\"Size of validation set, columns: {test_size[1]} and rows: {test_size[0]}\")\n",
    "\n",
    "# Show gender balance\n",
    "gender_count = df[\"label\"].value_counts()\n",
    "print(f\"Number of female audio recordings: {gender_count[0]}\")\n",
    "print(f\"Number of male audio recordings: {gender_count[1]}\")\n",
    "\n",
    "# Initialize classes\n",
    "XM = XGBoostModel(train_df, val_df, test_df)\n",
    "\n",
    "# Prepare datasets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = XM.prepare_data()\n",
    "\n",
    "# Hyperparameters tuning\n",
    "log_name = \"best_modeL_param.yaml\"\n",
    "#XM.grid_search(X_train, y_train, X_val, y_val, result_path, log_name, model_hyperparam)\n",
    "\n",
    "# Set model parameters\n",
    "XM.set_params(model_param)\n",
    "\n",
    "# Train model\n",
    "log_name = \"model_results.yaml\"\n",
    "XM.fit(X_train, y_train, X_val, y_val, result_path, log_name)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = XM.feature_importance()\n",
    "\n",
    "# Plot feature importance\n",
    "feat_imp_name = \"feature_importance.png\"\n",
    "DV.plot_feature_importance(feature_importance, test_df.iloc[:,:-1].columns, feat_imp_name)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = XM.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = XM.evaluate_predictions(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "\n",
    "# Read log file\n",
    "log_data = UT.read_file(os.path.join(result_path, log_name))\n",
    "\n",
    "# Load log data into pandas dataframe\n",
    "df = XM.create_log_df(log_data)\n",
    "\n",
    "# Plot training and validation loss\n",
    "loss_name = \"model_loss.png\"\n",
    "DV.plot_loss(df[\"iteration\"], df[\"train_loss\"], df[\"val_loss\"], loss_name)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "acc_name = \"model_accuracy.png\"\n",
    "DV.plot_accuracy(df[\"iteration\"], df[\"train_acc\"], df[\"val_acc\"], acc_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d23f3ceec305a45481076084313530cecc6283a24046b34365f00383ab0a81b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
